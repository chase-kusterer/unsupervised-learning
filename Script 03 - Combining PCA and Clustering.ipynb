{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h2>Script 03 | Combining PCA and Clustering</h2>\n",
    "<br>\n",
    "Written by Chase Kusterer<br>\n",
    "<a href=\"https://github.com/chase-kusterer\">GitHub</a> | <a href=\"https://www.linkedin.com/in/kusterer/\">LinkedIn</a>\n",
    "<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h2>Part I: Key Concepts</h2><br>\n",
    "\n",
    "<strong>Principal Component Analysis</strong><br>\n",
    "Operates on the variance between the x-features.<br><br>\n",
    "\n",
    "Three situations where PCA is useful:\n",
    "1. Correlated X-Features (which cannot be used together in many supervised learning models)\n",
    "2. Dimensionality Reduction (grouping large variable sets into a more manageable number of factors)\n",
    "3. Latent Trait Exploration (measuring what cannot be measured directly)\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<strong>Clustering</strong><br>\n",
    "Divide the data into groups, more formally known as clusters. One of the following will occur:\n",
    "* observations will be grouped based on their similarities\n",
    "* observations will be separated based on their differences\n",
    "\n",
    "<br>\n",
    "Reminder: Distance-based techniques require variance scaling.\n",
    "<br><br><br>\n",
    "<font color=\"red\"><strong><u>Don't forget!!!</u></strong></font>\n",
    "\n",
    "1. Don't mix data concepts in the same algorithm (spending behavior, demographics, psychometrics, etc.). \n",
    "2. Scale your data.\n",
    "3. Interpretation is subjective, so spend ample time on this step.\n",
    "\n",
    "<br>\n",
    "<strong>Run the following code to import the necessary packages for this analysis.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# importing packages\n",
    "########################################\n",
    "import numpy                 as np  # mathematical essentials\n",
    "import pandas                as pd  # data science essentials\n",
    "import matplotlib.pyplot     as plt # fundamental data visualization\n",
    "import seaborn               as sns # enhanced visualizations\n",
    "\n",
    "# packages for unsupervised learning\n",
    "from sklearn.preprocessing   import StandardScaler      # standard scaler\n",
    "from sklearn.decomposition   import PCA                 # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms\n",
    "from sklearn.cluster         import KMeans              # k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>Run the following code to load the dataset and set print options.</strong><br>\n",
    "Note that the values in each food category are revenue, but the currency units have been masked and the data has been treated for skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# loading data and setting display options\n",
    "########################################\n",
    "# loading data\n",
    "customers_df = pd.read_excel('./datasets/top_customers.xlsx')\n",
    "\n",
    "\n",
    "# setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "# checking results\n",
    "customers_df.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>User-Defined Functions</strong><br>\n",
    "Run the following code to load user-defined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     39
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('./analysis_images/top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "########################################\n",
    "# unsupervised_scaler\n",
    "########################################\n",
    "def scaler(df):\n",
    "    \"\"\"\n",
    "    Standardizes a dataset (mean = 0, variance = 1). Returns a new DataFrame.\n",
    "    Requires sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "\n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler(copy = True)\n",
    "\n",
    "\n",
    "    # FITTING the scaler with the data\n",
    "    scaler.fit(df)\n",
    "\n",
    "\n",
    "    # TRANSFORMING our data after fit\n",
    "    x_scaled = scaler.transform(df)\n",
    "\n",
    "    \n",
    "    # converting scaled data into a DataFrame\n",
    "    new_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "    # reattaching column names\n",
    "    new_df.columns = list(df.columns)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>b) Drop demographic information and scale the data.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# dropping demographic information\n",
    "_____\n",
    "\n",
    "\n",
    "# applying the unsupervised_scaler function\n",
    "purchases_scaled = scaler(df = ____)\n",
    "\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# dropping demographic information\n",
    "purchase_behavior = customers_df.drop(['Channel', 'Region'],\n",
    "                                      axis = 1)\n",
    "\n",
    "\n",
    "# applying the unsupervised_scaler function\n",
    "purchases_scaled = scaler(df = purchase_behavior)\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(np.var(purchase_behavior), '\\n\\n')\n",
    "print(np.var(purchases_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part II: Principal Component Analysis</h2>\n",
    "\n",
    "Our process here is to:\n",
    "1. Develop a PCA model with no limit to principal components\n",
    "2. Analyze the <strong>explained_variance_ratio</strong> and the <strong>scree plot</strong>\n",
    "3. Decide how many components to RETAIN\n",
    "4. Build a new model with a limited number of principal components\n",
    "5. Interpret the results\n",
    "\n",
    "<h4>a) Develop a PCA object with no limit to principal components and analyze its scree plot.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = _____(_____,\n",
    "          random_state = 702)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "customer_pca = _____._____(_____)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "_____(pca_object = _____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = None,\n",
    "          random_state = 702)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca = pca.fit_transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>b) Reduce the number of principal components to a reasonable number based on the scree plot above.</h4><br>\n",
    "In this example, we will assume three PCs is a reasonable number based on the elbow in the scree plot. Also note that it would have been reasonable to retain enough PCs so that the cumulative explained variance ratio is greater than or equal to 0.80. Note that we do not need to rerun the scree plot after completing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_3 = _____(_____,\n",
    "            _____ = 702)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca_3 = _____._____(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_3 = PCA(n_components = 3,\n",
    "            random_state = 702)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca_3 = pca_3.fit_transform(purchases_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<strong>OPTIONAL STEP</strong><br>Run the following code to compare the variance of the unlimited PCA model with the variance of the reduced PCA model. We are doing this in this script simply to show that the explained variance for each principal component does not change after dropping smaller PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### Max PC Model ###\n",
    "####################\n",
    "# transposing pca components (pc = MAX)\n",
    "factor_loadings = pd.DataFrame(np.transpose(pca.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings = factor_loadings.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "##################\n",
    "### 3 PC Model ###\n",
    "##################\n",
    "# transposing pca components (pc = 3)\n",
    "factor_loadings_3 = pd.DataFrame(np.transpose(pca_3.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_3 = factor_loadings_3.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(f\"\"\"\n",
    "MAX Components Factor Loadings\n",
    "------------------------------\n",
    "{factor_loadings.round(2)}\n",
    "\n",
    "\n",
    "3 Components Factor Loadings\n",
    "------------------------------\n",
    "{factor_loadings_3.round(2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>c) Analyze and name each principal component based on its factor loading.</h4>\n",
    "\n",
    "In this step, make sure to develop a story behind what each PC name represents. This is an ideal method for bridging the gap between the technical and non-technical people you are working with. Remember, by doing a good job here you are putting analytics at the forefront of strategic decision making, which is a great way to boost your value within an organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_3._____ = ['Protein Over Vitamins', # - Vegan, - Veg, - Indian\n",
    "                           'Sleeptime Bliss',       # - Med, - ME, - Wine\n",
    "                           'Palate Practicality']   # + Med,  - Wine\n",
    "\n",
    "\n",
    "# checking the result\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_3.columns = ['Protein Over Vitamins', # - Vegan, - Veg, - Indian\n",
    "                             'Sleeptime Bliss',       # - Med, - ME, - Wine\n",
    "                             'Palate Practicality']   # + Med,  - Wine\n",
    "\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_3.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>d) Analyze the factor loadings for each customer in the dataset.</h4>\n",
    "\n",
    "Do this by identifying groups of customers that have very high or very low factor loadings in any given principal component. A good heuristic is to look for factor loadings that are greater than one standard deviation from the mean in absolute value. Develop a strategy for key groups that you identify.<br><br>\n",
    "\n",
    "<strong>Don't forget</strong> to look at both the positive and negative loadings.<br>\n",
    "<strong>Don't forget</strong> to calculate the percentage of your audience effected by each loading when developing your targeting strategy/new ideas.<br>\n",
    "<strong>Don't forget</strong> to also consider the proportion of revenue generated by each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "factor_loadings = pca_3.transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "factor_loadings_df = _____._____(_____)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "factor_loadings_df.columns = factor_loadings_3.columns\n",
    "\n",
    "\n",
    "# checking the results\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "factor_loadings = pca_3.transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "factor_loadings_df = pd.DataFrame(factor_loadings)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "factor_loadings_df.columns = factor_loadings_3.columns\n",
    "\n",
    "\n",
    "# checking the results\n",
    "factor_loadings_df.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "Sending PCA factor loadings to Excel for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "factor_loadings_df.to_excel('./analysis_results/PCA Factor Loadings.xlsx',\n",
    "                            index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part III: Intro to Clustering</h2><br>\n",
    "We are going to start by building an agglomerative clustering model. We are primarily interested in the <strong>dendrogram</strong> and the <strong>inertia plot</strong>. Our goal is to develop an idea as to how many clusters would be appropriate given our analysis of these tools, and then to apply this number of clusters to a k-Means model. Try to come away with 4-5 different numbers of clusters so that you have more options when applying k-Means. <strong>Before getting started, we need to rescale our data.</strong> The reason is that the variance amongst our features is no longer equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# checking variance amongst clusters\n",
    "np.var(factor_loadings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>a) Complete the code to prepare a scaled version of the factor loadings dataset.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# applying the unsupervised_scaler function\n",
    "pca_rescaled = _____\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(np.var(factor_loadings_df), '\\n\\n')\n",
    "print(np.var(pca_rescaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# applying the unsupervised_scaler function\n",
    "pca_rescaled = scaler(df = factor_loadings_df)\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(np.var(factor_loadings_df), '\\n\\n')\n",
    "print(np.var(pca_rescaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part IV: Agglomerative Clustering</h2><br>\n",
    "Agglomerative clustering starts with each observation in its own cluster. From here, it links observations  based on distance. There are three primary methods for calculating distance:<br><br>\n",
    "\n",
    "    ward (default) - groups observations into clusters in a way that minimizes \n",
    "    the variance amongst all clusters. Leads to clusters that are relatively\n",
    "    equal in size\n",
    "\n",
    "    average - merges clusters that have the smallest average distance\n",
    "    between all their points\n",
    "\n",
    "    complete - merges clusters that have the smallest maximum distance\n",
    "    between their points\n",
    "\n",
    "<br><br>\n",
    "<u>Primary Advantage</u><br>\n",
    "Able to generate a dendrogram to better understand data groupings and help determine the final number of clusters to develop.\n",
    "<br><br>\n",
    "<u>Primary Disadvantage</u><br>\n",
    "Unable to predict on new data.<br><br>\n",
    "\n",
    "Run the following code to develop a dendrogram. Our goal here is to understand how many clusters to build using k-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y = pca_rescaled,\n",
    "                                 method = 'ward',\n",
    "                                 optimal_ordering = True)\n",
    "\n",
    "\n",
    "# setting plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation  = 90       ,\n",
    "           leaf_font_size = 6        )\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>a) Complete the code to develop a k-Means model with three clusters.</h4>\n",
    "This is where we test our candidate number of clusters. When we find a clustering that we like, we move forward. For this example, let's assume we converged on a solution of three clusters.<br><br>\n",
    "<strong>Don't forget</strong> that the appropriate number of clusters does not have to be the same as the number of principal components that were retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a k-Means object with five clusters\n",
    "customers_k_pca = _____(n_clusters   = 3     ,\n",
    "                        n_init       = 'auto',\n",
    "                        random_state = 702   )\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca._____(_____)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = _____._____({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a k-Means object with clusters\n",
    "customers_k_pca = KMeans(n_clusters   = 3     ,\n",
    "                         n_init       = 'auto',\n",
    "                         random_state = 702   )\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(pca_rescaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>b) Finish the code to display the centroids (mean values) for each cluster.</h4>\n",
    "When you are finished, interpret their meaning. This is also a place where you may want to (optionally) name your clusters and develop back stories for ideal members of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_pca = customers_k_pca._____\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = pd.DataFrame(_____).round(decimals = 2)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df._____ = _['Protein Over Vitamins',\n",
    "                           'Sleeptime Bliss',\n",
    "                           'Palate Practicality']\n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_pca = customers_k_pca.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca).round(decimals = 2)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df.columns = ['Protein Over Vitamins',\n",
    "                             'Sleeptime Bliss',\n",
    "                             'Palate Practicality']\n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h4>c) Run the following code to concatenate channel, region, and the PCA components into one DataFrame.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# concatenating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([customers_kmeans_pca,\n",
    "                         factor_loadings_df],\n",
    "                         axis = 1)\n",
    "\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_df = pd.concat([customers_df.loc[ : , ['Channel', 'Region']],\n",
    "                      clst_pca_df.round(decimals = 2)],\n",
    "                      axis = 1)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "final_df.columns = ['Channel', 'Region', 'Cluster',\n",
    "                    'Protein Over Vitamins',\n",
    "                    'Sleeptime Bliss',\n",
    "                    'Palate Practicality']\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(final_df.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "Run the following code to add labels to categorical variables. If you (optionally) named your clusters, make sure to label these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# renaming channels\n",
    "channel_names = {1 : 'Online',\n",
    "                 2 : 'Mobile'}\n",
    "\n",
    "\n",
    "final_df['Channel'].replace(channel_names, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# renaming regions\n",
    "region_names = {1 : 'Alameda',\n",
    "                2 : 'San Francisco',\n",
    "                3 : 'Contra Costa'}\n",
    "\n",
    "\n",
    "final_df['Region'].replace(region_names, inplace = True)\n",
    "\n",
    "\n",
    "# renaming regions\n",
    "cluster_names = {0 : '1',\n",
    "                 1 : '2',\n",
    "                 2 : '3'}\n",
    "\n",
    "\n",
    "final_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "\n",
    "# checking results\n",
    "final_df.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part V: Analyze with Demographics</h2><br>\n",
    "Now that we've completed all of our preparation through machine learning, we can analyze our results with demographics and other data.<br><br>\n",
    "<strong>Pause before this step</strong> so that you can consider all of the hypotheses and assumptions you have made up to this point. Also consider all of the assumptions your organization is making. For example, if the company is convinced of a particular trend, the following is a good opportunity to validate/negate that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# dynamic string with value counts for each demographic (cluster 1)\n",
    "print(f\"\"\"\\\n",
    " -----------\n",
    "| Cluster 1 |\n",
    " -----------\n",
    "\n",
    "Proportion of Observations\n",
    "--------------------------\n",
    "{round(len(final_df.loc[ : , \"Cluster\"][final_df.loc[ : , \"Cluster\"] == '1']) /\n",
    "       len(final_df), ndigits = 2)}\n",
    "\n",
    "\n",
    "Centroids\n",
    "---------\n",
    "{centroids_pca_df.loc[ 0 , :].to_string(dtype = False, name = False)}\n",
    "\n",
    "\n",
    "Channel\n",
    "-------\n",
    "{final_df.loc[ : , \"Channel\"][ final_df.loc[ : , 'Cluster' ] == '1']\n",
    "\n",
    "         .value_counts(normalize = True)\n",
    "         .round(decimals = 2)\n",
    "         .sort_index().to_string(dtype = False, name = False)}\n",
    "  \n",
    "  \n",
    "Region\n",
    "------\n",
    "{final_df.loc[ : , \"Region\"][ final_df.loc[ : , 'Cluster' ] == '1']\n",
    "\n",
    "         .value_counts(normalize = True)\n",
    "         .round(decimals = 2)\n",
    "         .sort_index().to_string(dtype = False, name = False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# dynamic string with value counts for each demographic (cluster 2)\n",
    "print(f\"\"\"\\\n",
    " -----------\n",
    "| Cluster 2 |\n",
    " -----------\n",
    "\n",
    "Proportion of Observations\n",
    "--------------------------\n",
    "{round(len(final_df.loc[ : , \"Cluster\"][final_df.loc[ : , \"Cluster\"] == '2']) /\n",
    "       len(final_df), ndigits = 2)}\n",
    "\n",
    "\n",
    "Centroids\n",
    "---------\n",
    "{centroids_pca_df.loc[ 1 , :].to_string(dtype = False, name = False)}\n",
    "\n",
    "\n",
    "Channel\n",
    "-------\n",
    "{final_df.loc[ : , \"Channel\"][ final_df.loc[ : , 'Cluster' ] == '2']\n",
    "\n",
    "         .value_counts(normalize = True)\n",
    "         .round(decimals = 2)\n",
    "         .sort_index().to_string(dtype = False, name = False)}\n",
    "  \n",
    "  \n",
    "Region\n",
    "------\n",
    "{final_df.loc[ : , \"Region\"][ final_df.loc[ : , 'Cluster' ] == '2']\n",
    "\n",
    "         .value_counts(normalize = True)\n",
    "         .round(decimals = 2)\n",
    "         .sort_index().to_string(dtype = False, name = False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# dynamic string with value counts for each demographic (cluster 3)\n",
    "print(f\"\"\"\\\n",
    " -----------\n",
    "| Cluster 3 |\n",
    " -----------\n",
    "\n",
    "Proportion of Observations\n",
    "--------------------------\n",
    "{round(len(final_df.loc[ : , \"Cluster\"][final_df.loc[ : , \"Cluster\"] == '3']) /\n",
    "       len(final_df), ndigits = 2)}\n",
    "\n",
    "\n",
    "Centroids\n",
    "---------\n",
    "{centroids_pca_df.loc[ 2 , :].to_string(dtype = False, name = False)}\n",
    "\n",
    "\n",
    "Channel\n",
    "-------\n",
    "{final_df.loc[ : , \"Channel\"][ final_df.loc[ : , 'Cluster' ] == '3']\n",
    "\n",
    "         .value_counts(normalize = True)\n",
    "         .round(decimals = 2)\n",
    "         .sort_index().to_string(dtype = False, name = False)}\n",
    "  \n",
    "  \n",
    "Region\n",
    "------\n",
    "{final_df.loc[ : , \"Region\"][ final_df.loc[ : , 'Cluster' ] == '3']\n",
    "\n",
    "         .value_counts(normalize = True)\n",
    "         .round(decimals = 2)\n",
    "         .sort_index().to_string(dtype = False, name = False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "~~~\n",
    "\n",
    "                               _             _ \n",
    "     /\\                       (_)           | |\n",
    "    /  \\   _ __ ___   __ _ _____ _ __   __ _| |\n",
    "   / /\\ \\ | '_ ` _ \\ / _` |_  / | '_ \\ / _` | |\n",
    "  / ____ \\| | | | | | (_| |/ /| | | | | (_| |_|\n",
    " /_/    \\_\\_| |_| |_|\\__,_/___|_|_| |_|\\__, (_)\n",
    "                                        __/ |  \n",
    "                                       |___/                                                             \n",
    "~~~\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
