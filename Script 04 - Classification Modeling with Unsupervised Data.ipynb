{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f85a745",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h2>Script 04 | Classification Modeling with Unsupervised Data</h2>\n",
    "<br>\n",
    "Written by Chase Kusterer<br>\n",
    "<a href=\"https://github.com/chase-kusterer\">GitHub</a> | <a href=\"https://www.linkedin.com/in/kusterer/\">LinkedIn</a>\n",
    "<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9d01a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h3>Introduction</h3><br>\n",
    "Now that we have an understanding of unsupervised learning through principal component analysis and k-means clustering, we are ready to apply the results of these algorithms to a supervised learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3f8e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np                                          # mathematical essentials\n",
    "import pandas as pd                                         # data science essentials\n",
    "from sklearn.decomposition import PCA                       # principal component analysis\n",
    "from sklearn.model_selection import train_test_split        # train-test split\n",
    "from sklearn.preprocessing import StandardScaler            # data prep\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score # results analysis\n",
    "from sklearn.cluster import KMeans                          # k-means clustering\n",
    "import sklearn.linear_model                                 # classification modeling\n",
    "\n",
    "\n",
    "\n",
    "# importing data\n",
    "file    = './datasets/ames_classification.xlsx'\n",
    "housing = pd.read_excel(io = file)\n",
    "\n",
    "\n",
    "# checking results\n",
    "housing.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582df56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a947e",
   "metadata": {
    "code_folding": [
     1
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# standard_scaler\n",
    "def standard_scaler(df):\n",
    "    \"\"\"\n",
    "    Standardizes a dataset (mean = 0, variance = 1). Returns a new DataFrame.\n",
    "    Requires sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "\n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler(copy = True)\n",
    "\n",
    "\n",
    "    # FITTING the scaler with the data\n",
    "    scaler.fit(df)\n",
    "\n",
    "\n",
    "    # TRANSFORMING our data after fit\n",
    "    x_scaled = scaler.transform(df)\n",
    "\n",
    "    \n",
    "    # converting scaled data into a DataFrame\n",
    "    new_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "    # reattaching column names\n",
    "    new_df.columns = list(df.columns)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d23e208",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<h3>Classification Modeling with Principal Components</h3><br>\n",
    "Let's assume we have already conducted principal component analysis and came to the conclusion that we will retain four principal components. Note that there was no actual analysis conducted and if so, we would likely arrive at a different number of retained principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2785e47",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# subsetting continuous data\n",
    "housing_continuous = housing[ ['Lot_Area', 'Mas_Vnr_Area', 'Total_Bsmt_SF',\n",
    "                               'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area',\n",
    "                               'Garage_Area', 'Porch_Area'] ]\n",
    "\n",
    "\n",
    "# scaling the data\n",
    "pca_data = standard_scaler(df = housing_continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f5bc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc003b",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object\n",
    "pca = PCA(n_components = _____,\n",
    "          random_state = 702)\n",
    "\n",
    "\n",
    "# preparing factor loadings\n",
    "housing_pca = pca.fit_transform(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077571a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object\n",
    "pca = PCA(n_components = 4,\n",
    "          random_state = 702)\n",
    "\n",
    "\n",
    "# preparing factor loadings\n",
    "housing_pca = pca.fit_transform(pca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58a797",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebadae7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#?# Do we get better results when we scale the factor loadings? #?#\n",
    "#housing_pca_scaled = standard_scaler(df = pd.DataFrame(data = housing_pca))\n",
    "\n",
    "\n",
    "# selecting x- and y-data\n",
    "x_data = housing_pca\n",
    "y_data = housing['Expensive_Property']\n",
    "\n",
    "\n",
    "# training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                    y_data,\n",
    "                                                    test_size    = 0.25,\n",
    "                                                    random_state = 702,\n",
    "                                                    stratify     = y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58e8ec",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3363c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "model = sklearn.linear_model.LogisticRegression(solver       = 'lbfgs',\n",
    "                                                C            = 1,\n",
    "                                                random_state = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model_fit.predict(x_test) # predict_proba for multiclass\n",
    "\n",
    "\n",
    "# checking results\n",
    "train_acc = model_fit.score(x_train, y_train)\n",
    "test_acc  = model_fit.score(x_test , y_test )\n",
    "roc_score = roc_auc_score  (y_true      = y_test,\n",
    "                            y_score     = model_pred)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "Train-Test Gap: {round(abs(train_acc - test_acc), ndigits = 3)}\n",
    "Test AUC Score: {roc_score.round(decimals = 3)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f3b77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53375c45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "model_tn, \\\n",
    "model_fp, \\\n",
    "model_fn, \\\n",
    "model_tp = confusion_matrix(y_true = y_test, y_pred = model_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {model_tn}\n",
    "False Positives: {model_fp}\n",
    "False Negatives: {model_fn}\n",
    "True Positives : {model_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b3491",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<h3>Classification Modeling with Clusters</h3><br>\n",
    "Let's assume we also have already conducted principal component analysis and came to the conclusion that we will retain five clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed15680",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# standardizing the data for clustering\n",
    "pca_rescaled = standard_scaler(df = pd.DataFrame(data = housing_pca))\n",
    "\n",
    "\n",
    "# INSTANTIATING a k-Means object with clusters\n",
    "customers_k_pca = KMeans(n_clusters   = _____ ,\n",
    "                         n_init       = 'auto',\n",
    "                         random_state = 702   )\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(pca_rescaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking cluster populations\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18208c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# standardizing the data for clustering\n",
    "pca_rescaled = standard_scaler(df = pd.DataFrame(data = housing_pca))\n",
    "\n",
    "\n",
    "# INSTANTIATING a k-Means object with clusters\n",
    "customers_k_pca = KMeans(n_clusters   = 5     ,\n",
    "                         n_init       = 'auto',\n",
    "                         random_state = 702   )\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(pca_rescaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking cluster populations\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6808ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c680cd3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# checking which observations belong to each cluster\n",
    "customers_kmeans_pca.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df41100",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "It a best practice to treat clusters as a categorical feature and assume they have no inherent order. In other words, we should assume that each cluster is independent. This also fits with one of the assumptions of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e78038",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# factorizing cluster results \n",
    "cluster_df = pd.get_dummies(data       = customers_kmeans_pca['Cluster'],\n",
    "                            drop_first = True).astype(dtype = int)\n",
    "\n",
    "\n",
    "# checking results\n",
    "cluster_df.value_counts(normalize = False).sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e31a66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6e6b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# selecting x- and y-data\n",
    "x_data = cluster_df\n",
    "y_data = housing['Expensive_Property']\n",
    "\n",
    "\n",
    "# training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                    y_data,\n",
    "                                                    test_size    = 0.25,\n",
    "                                                    random_state = 702,\n",
    "                                                    stratify     = y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77283ebe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f34e7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "model = sklearn.linear_model.LogisticRegression(solver       = 'lbfgs',\n",
    "                                                C            = 1,\n",
    "                                                random_state = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model_fit.predict(x_test) # predict_proba for multiclass\n",
    "\n",
    "\n",
    "# checking results\n",
    "train_acc = model_fit.score(x_train, y_train)\n",
    "test_acc  = model_fit.score(x_test , y_test )\n",
    "roc_score = roc_auc_score  (y_true  = y_test,\n",
    "                            y_score = model_pred)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "Train-Test Gap: {round(abs(train_acc - test_acc), ndigits = 3)}\n",
    "Test AUC Score: {round(roc_score, ndigits = 3)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d853754",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6999c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_pca = pd.DataFrame(data = customers_k_pca.cluster_centers_)\n",
    "\n",
    "\n",
    "# checking cluster centers\n",
    "centroids_pca.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d246f41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc255f1a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "model_tn, \\\n",
    "model_fp, \\\n",
    "model_fn, \\\n",
    "model_tp = confusion_matrix(y_true = y_test, y_pred = model_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {model_tn}\n",
    "False Positives: {model_fp}\n",
    "False Negatives: {model_fn}\n",
    "True Positives : {model_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab1c98",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    " __     __                               _        _ _   _ \n",
    " \\ \\   / /                              | |      (_) | | |\n",
    "  \\ \\_/ /__  _   _   _ __ ___   __ _  __| | ___   _| |_| |\n",
    "   \\   / _ \\| | | | | '_ ` _ \\ / _` |/ _` |/ _ \\ | | __| |\n",
    "    | | (_) | |_| | | | | | | | (_| | (_| |  __/ | | |_|_|\n",
    "    |_|\\___/ \\__,_| |_| |_| |_|\\__,_|\\__,_|\\___| |_|\\__(_)\n",
    "     \n",
    "     \n",
    "                                                          \n",
    "~~~\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9dd8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.355px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
